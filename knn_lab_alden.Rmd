---
title: "KNN Lab"
author: "Alden Summerville"
date: "10/27/2020"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)

library(tidyverse)
library(ggplot2)
library(class)
library(caret)
library(scatterplot3d)


```

## Objective

You left your job as a lobbyist because the political environment was become just too toxic to handle.  Luckily you landed a job in advertising! Unfortunately have a demanding and totally clueless boss. Clueless meaning that he doesn't understand data science, but he knows he wants it to be used to fix all the company's problems and you are just the data scientist to do it! 

Your company, Marketing Enterprises of Halifax or "MEH" is being beat out by the competition and wants a new way to determine the quality of its commercials. Your boss, Mr. Ed Rooney, would like the company's commercials to seem more like actual TV shows. So we wants you to develop a "machine learning thing" using the companyâ€™s internal data to classify when something is a commercial and when it is not. Mr. Rooney believes the company will then know how to trick potential future customers into thinking their commercials are actually still part of the show and as a result will pay more attention and thus buy more of the terrible products "MEH" is supporting (it's a terrible plan, but you have to make a living). 

Given that MEH is producing commercials more or less continuously you know there will be a need to update the model quite frequently, also being a newish data scientist and having a clueless boss you decide to use a accessible approach that you might be able to explain to Mr. Rooney, (given several months of dedicated one on one time), that approach is k-nearest neighbor. 

You'll also need to document your work extensively, because Mr. Rooney doesn't know he's clueless so he will ask lots of "insightful" questions and require lots of detail that he won't understand, so you'll need to have an easy to use reference document. Before you get started you hearken back to the excellent education you received at UVA and using this knowledge outline roughly 20 steps that need to be completed to build this algo for MEH and Ed, they are documented below...good luck. As always, the most important part is translating your work to actionable insights, so please make sure to be verbose in the explanation required for step 20.  

As with the clustering lab, please be prepared to present a five minute overview of your findings. 
 

## kNN Analysis

```{r}
#1
#Load in the data, both the commercial dataset and the labels. You'll need to the place the labels on the columns. The dataset "tv_commercialsets-CNN_Cleaned.csv",  is data collected about the features of commercials on CNN. We can try to predict what segments of video are commercials based on their audio and video components. More information on the datasets can be found data.world:
# https://data.world/kramea/tv-commercial-detection/workspace/file?filename=tv_commercial_datasets%2FBBC_Cleaned.csv

#You can use the function colnames() to apply the labels (hint: you might need to reshape the labels to make this work)

CNN_commercials <- read.csv("tv_commercial_datasets_CNN_Cleaned.csv")
CNN_labels = read.csv("cnn_commmercial_label.csv", header=FALSE)
colnames(CNN_commercials) = CNN_labels[,1]


```

```{r}
#2. Determine the split between commercial and non-commercial then calculate the base rate, assume 1 is the commercial label and -1 is the non-commercial label 

table(CNN_commercials$`label`)
table(CNN_commercials$`label`)[2] / sum(table(CNN_commercials$`label`))

```

Therefore, baseline rate of commercials to non-commercials is 63.92%.

```{r}
#3. Since there are columns that contain different metrics for the same variable (i.e. any column that ends in 'mn' is the mean of that variable, while any column that ends in 'var' is the variance of that variable), we don't need to keep both, drop all the columns that include var

CNN_commercials <- select(CNN_commercials, -ends_with("var"))

```

```{r}
#4.  Before we run knn, sometimes it's good to check to make sure that our variables are not highly correlated. Use the cor() function on 'your_dataframe', label it 'commercial_correlations', and view the data.

commercial_correlations <- cor(CNN_commercials)

```

```{r}
#5. Determine which variables to remove, high correlations start around .7 or below -.7 I would especially remove variables that appear to be correlated with more than one variable. List your rationale here:

mean(abs(as.data.frame(commercial_correlations)$motion_distr_mn))
mean(abs(as.data.frame(commercial_correlations)$motion_dist_mn))
mean(abs(as.data.frame(commercial_correlations)$spectral_centroid_mn))
mean(abs(as.data.frame(commercial_correlations)$spectral_roll_off_mn))
mean(abs(as.data.frame(commercial_correlations)$spectral_flux_mn))

#remove: 
#motion_distr_mn - correlations over +-0.7 with 2 other variables and a very low (~0.05) correlation with the label.
#spectral_centroid_mn - correlation over 0.8 with one variable and generally high correlations with multiple other variables. Primarily correlated with spectral_roll_off_mn, but we'll keep that variable because the mean correlation is lower than spectral_centroid_mn.
#spectral_flux_mn - Extremely high correlation of over 0.8 with short_time_energy_mn. We'll keep the short_time_energy_mn because the mean correlation is lower than the spectral flux.

#These must be removed because their high correlations will have a biased pull on the modeling.

```

Columns removed due to high correlations:

- motion_distr_mn

- spectral_centroid_mn

- spectral_flux_mn


```{r}
#6. Subset the dataframe based on above.

CNN_commercials <- select(CNN_commercials, -motion_distr_mn, -spectral_centroid_mn, -spectral_flux_mn)

```


```{r}
#7. Now we have our data and are ready to run the KNN, but we need to split into test and train. Create a index the will divide the data into a 70/30 split

CNN_index <- round(0.7 * nrow(CNN_commercials), 0)

```

```{r}
#8. Use the index above to generate a train and test sets, then check the row counts to be safe and show Mr. Rooney. 

set.seed(10271999)

CNN_train_rows <- sample(1:nrow(CNN_commercials), 
                         CNN_index, 
                         replace = FALSE)

#generate train and test sets
CNN_train <- CNN_commercials[CNN_train_rows, ]
CNN_test <- CNN_commercials[-CNN_train_rows, ]

#check train set
nrow(CNN_train)/(nrow(CNN_train)+nrow(CNN_test)) #0.7
nrow(CNN_train)
nrow(CNN_test)

```

```{r}
#9 Train the classifier using k = 3, remember to set.seed so you can repeat the output and to use the labels as a vector for the class (not a index of the dataframe)

CNN_KNN <- knn(train = CNN_train[, 1:7],
               test = CNN_test[, 1:7],  
               cl = CNN_train$`label `,
               k = 3,
               use.all = TRUE,
               prob = TRUE)

```


```{r}
#10 Check the output using str and length just to be sure it worked

str(CNN_KNN)
length(CNN_KNN)

```

```{r}
#11 Create a initial confusion matrix using the table function and pass it to a object. (xx <- your confusion matrix)

CNN_conf_matrix <- table(CNN_KNN, CNN_test$`label `)
CNN_conf_matrix

```

```{r}
#12 Select the true positives and true negatives by selecting only the cells where the row and column names are the same.

CNN_conf_matrix[row(CNN_conf_matrix) == col(CNN_conf_matrix)]


```

```{r}
#13 Calculate the accuracy rate by dividing the correct classifications by the total number of classifications. Label the data 'kNN_acc_com', and view it. Comment on how this compares to the base rate. 

kNN_acc_com <- sum(CNN_conf_matrix[row(CNN_conf_matrix) == col(CNN_conf_matrix)])/sum(CNN_conf_matrix)
kNN_acc_com



```

Accuracy rate of 73.17% compared to a base accuracy rate of 63.92%. Therefore, there was an increase in about 10% accuracy using our machine learning model.

```{r}
#14  Run the confusion matrix function and comment on the model output

confusionMatrix(as.factor(CNN_KNN), as.factor(CNN_test$`label `), positive = "1", dnn=c("Prediction", "Actual"), mode = "sens_spec")

```

Our Sensitivity model represents our skill and rate in being correct when guessing that something is a commercial. The 3-nearest neighbor model produces a Sensitivity output of 83.03%. We want to make sure that this value is maximized (as opposed to the correct negative percentage, which is represented by the Specificity model), as we want to apply this model to our own commercials and check if they are detected correctly.

```{r}
#15 Run the "chooseK" function to find the perfect K, while using sapply() function on chooseK() to test k from 1 to 21 (only selecting the odd numbers), and set the train_set argument to 'commercial_train', val_set to 'commercial_test', train_class to the "label"   column of 'commercial_train', and val_class to the "label" column of 'commercial_test'. Label this  "knn_diff_k_com"

chooseK = function(k, train_set, val_set, train_class, val_class){
  
  # Build knn with k neighbors considered.
  set.seed(1)
  class_knn = knn(train = train_set,    #<- training set cases
                  test = val_set,       #<- test set cases
                  cl = train_class,     #<- category for classification
                  k = k,                #<- number of neighbors considered
                  use.all = TRUE)       #<- control ties between class assignments
                                        #   If true, all distances equal to the kth largest are included
  conf_mat = table(class_knn, val_class)
  
  # Calculate the accuracy.
  accu = sum(conf_mat[row(conf_mat) == col(conf_mat)]) / sum(conf_mat)                         
  cbind(k = k, accuracy = accu)
}


knn_diff_k_com = sapply(seq(1, 21, by = 2),
                         function(x) chooseK(x, 
                                             train_set = CNN_train[, 1:7],
                                             val_set = CNN_test[, 1:7],
                                             train_class = CNN_train$`label `,
                                             val_class = CNN_test$`label `))


```

```{r}
#16 Create a dataframe so we can visualize the difference in accuracy based on K, convert the matrix to a dataframe

k_output = data.frame(k = knn_diff_k_com[1,],
                             accuracy = knn_diff_k_com[2,])
k_output


```

```{r}
#17 Use ggplot to show the output and comment on the k to select

ggplot(k_output,
       aes(x = k, y = accuracy)) +
  geom_line(color = "orange", size = 1.5) +
  geom_point(size = 3)


```

The accuracy marginally improves until k=11, after which it starts to actually decrease; therefore, the optimal k option for our model is k = 11.

```{r}
#18 Rerun the model  with "optimal" k 

CNN_KNN_optimal <- knn(train = CNN_train[, 1:7],
               test = CNN_test[, 1:7],  
               cl = CNN_train$`label `,
               k = 11,
               use.all = TRUE,
               prob = TRUE)


```

```{r}
#19 Use the confusion matrix function to measure the quality of the new model

confusionMatrix(as.factor(CNN_KNN_optimal), as.factor(CNN_test$`label `), positive = "1", dnn=c("Prediction", "Actual"), mode = "sens_spec")

#Accuracy = 76.35%
#Sensitivity = 88.65%


```

```{r}
#20 Summarize the differences in language Mr. Rooney may actually understand. Include a discussion on which approach (number of k's)* is the better method moving forward for "MEH". Most importantly draft comments about the over approach and model quality as it relates to addressing the problem proposed by Ed. 

```

## Summary

Mr. Rooney, after building your desired machine learning model, I was able to increase the prediction rate of a commercial vs. a non-commercial by around 13%. By utilizing a "k-nearest neighbor" algorithm and adjusting the parameters to include data that would give us optimal results, the model correctly predicted a commercial 76% of the time. The model did this by calculating something called a "euclidean distance" which is basically the distance between a point we wish to label and other known points. By optimizing the number of known points the model searches for to classify an unknown point, the model was able to reach a prediction accuracy of 76% with a sensitivity of 89%. Compared to the rate of 63% for correct predictions with no given information (the baseline rate), my model is valid and could be applied in the field. Another advantage of this model is that it can be re-trained if given new data and can be continuously updated to reflect changes or trends in modern TV commercials. 
