---
title: "KNN Lab"
author: "Aatmika Deshpande"
date: "4/7/2020"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

You left your job as a lobbyist because the political environment was become just too toxic to handle.  Luckily you landed a job in advertising! Unfortunately have a demanding and totally clueless boss. Clueless meaning that he doesn't understand data science, but he knows he wants it to be used to fix all the company's problems and you are just the data scientist to do it! 

Your company, Marketing Enterprises of Halifax or "MEH" is being beat out by the competition and wants a new way to determine the quality of its commercials. Your boss, Mr. Ed Rooney, would like the company's commercials to seem more like actual TV shows. So we wants you to develop a "machine learning thing" using the companyâ€™s internal data to classify when something is a commercial and when it is not. Mr. Rooney believes the company will then know how to trick potential future customers into thinking their commercials are actually still part of the show and as a result will pay more attention and thus buy more of the terrible products "MEH" is supporting (it's a terrible plan, but you have to make a living). 

Given that MEH is producing commercials more or less continuously you know there will be a need to update the model quite frequently, also being a newish data scientist and having a clueless boss you decide to use a accessible approach that you might be able to explain to Mr. Rooney, (given several months of dedicated one on one time), that approach is k-nearest neighbor. 

You'll also need to document your work extensively, because Mr. Rooney doesn't know he's clueless so he will ask lots of "insightful" questions and require lots of detail that he won't understand, so you'll need to have an easy to use reference document. Before you get started you hearken back to the excellent education you received at UVA and using this knowledge outline roughly 20 steps that need to be completed to build this algo for MEH and Ed, they are documented below...good luck. As always, the most important part is translating your work to actionable insights, so please make sure to be verbose in the explanation required for step 20.  

As with the clustering lab, please be prepared to present a five minute overview of your findings. 
 

```{r}
#1
#Load in the data, both the commercial dataset and the labels. You'll need to the place the labels on the columns. The dataset "tv_commercialsets-CNN_Cleaned.csv",  is data collected about the features of commercials on CNN. We can try to predict what segments of video are commercials based on their audio and video components. More information on the datasets can be found data.world:
# https://data.world/kramea/tv-commercial-detection/workspace/file?filename=tv_commercial_datasets%2FBBC_Cleaned.csv

#You can use the function colnames() to apply the labels (hint: you might need to reshape the labels to make this work)

CNN_commercials = read.csv("tv_commercial_datasets_CNN_Cleaned.csv")
CNN_labels = read.csv("cnn_commmercial_label.csv", header=FALSE)
labels = CNN_labels[,1]
colnames(CNN_commercials) = labels
```

```{r}
#2. Determine the split between commercial and non-commercial then calculate the base rate, assume 1 is the commercial label and -1 is the non-commercial label 
table(CNN_commercials$label)
table(CNN_commercials$label)[2]/sum(table(CNN_commercials$label))
```
The base rate for a commercial label is .6392. This means that at random, we have a 63.92% change of correctly picking out whether or not something running on TV is a commercial or not. 

```{r}
#3. Since there are columns that contain different metrics for the same variable (i.e. any column that ends in 'mn' is the mean of that variable, while any column that ends in 'var' is the variance of that variable), we don't need to keep both, drop all the columns that include var

library(tidyverse)
CNN_commercials = CNN_commercials %>% select(-ends_with("var"))
```

```{r}
#4.  Before we run knn, sometimes it's good to check to make sure that our variables are not highly correlated. Use the cor() function on 'your_dataframe', label it 'commercial_correlations', and view the data.
commercial_correlations = cor(CNN_commercials)
View(commercial_correlations)
```

```{r}
#5. Determine which variables to remove, high correlations start around .7 or below -.7 I would especially remove variables that appear to be correlated with more than one variable. List your rationale here:
mean(as.data.frame(commercial_correlations)$spectral_flux_mn)
mean(as.data.frame(commercial_correlations)$short_time_energy_mn)
mean(as.data.frame(commercial_correlations)$spectral_roll_off_mn)
mean(as.data.frame(commercial_correlations)$spectral_centroid_mn)
```
After observing the correlation matrix, we will be removing motion_distr_mn due to a very strong negative correlation of -0.758 with motion_dist_mn, and its is fairly strong positive correlation of 0.716 with frame_diff_dist_mn. spectral_flux_mn and short_time_energy_mn have a correlation even larger than the other two of 0.823, so one of these must be removed to account for the correlation. We chose to remove spectral_flux_mn because it had an every so slightly stronger general correlation with all the variables in the dataset than short_time_energy, and more correlations above 0.1 in general. spectral_roll_off_mn and spectral_centroid_mn have a positive correlation of 0.809, so one of these two will be removed as well. We chose to remove spectral_centroid because it's average correlation with all the variables was 0.278, compared to spectral_roll_off_mn's average being 0.220. These correlated variables would have a biased impact on the kNN modeling that is to be done, which is why they must be removed. 

To summarize, the variables that show some sort of high correlation and are going to be removed are: 
- motion_distr_mn
- spectral_flux_mn
- spectral_centroid_mn

```{r}
#6. Subset the dataframe based on above.
CNN_commercials = CNN_commercials %>% select(
-motion_distr_mn,
-spectral_flux_mn,
-spectral_centroid_mn)
```


```{r}
#7. Now we have our data and are ready to run the KNN, but we need to split into test and train. Create a index the will divide the data into a 70/30 split
index = round(0.7 * nrow(CNN_commercials), 0)
index
```

```{r}
#8. Use the index above to generate a train and test sets, then check the row counts to be safe and show Mr. Rooney. 
set.seed(10271999)

CNN_comm_train_rows = sample(1:nrow(CNN_commercials),
                              index,
                              replace = FALSE)

CNN_comm_train = CNN_commercials[CNN_comm_train_rows,]
CNN_comm_test = CNN_commercials[-CNN_comm_train_rows,]

#70% training
nrow(CNN_comm_train)/nrow(CNN_commercials)
#30% testing
nrow(CNN_comm_test)/nrow(CNN_commercials)
```

```{r}
#9 Train the classifier using k = 3, remember to set.seed so you can repeat the output and to use the labels as a vector for the class (not a index of the dataframe)
library(class)

set.seed(10271999)

CNN_3NN <-  knn(train = CNN_comm_train[, 1:7],
               test = CNN_comm_test[, 1:7],    
               cl = CNN_comm_train$label,
               k = 3,
               use.all = TRUE,
               prob = TRUE)

```


```{r}
#10 Check the output using str and length just to be sure it worked
str(CNN_3NN)
length(CNN_3NN)
```

```{r}
#11 Create a initial confusion matrix using the table function and pass it to a object. (xx <- your confusion matrix)
CNN_kNN_res = table(CNN_3NN,
                CNN_comm_test$label)
CNN_kNN_res
```

```{r}
#12 Select the true positives and true negatives by selecting only the cells where the row and column names are the same.
CNN_kNN_res[row(CNN_kNN_res) == col(CNN_kNN_res)]
```

```{r}
#13 Calculate the accuracy rate by dividing the correct classifications by the total number of classifications. Label the data 'kNN_acc_com', and view it. Comment on how this compares to the base rate. 
CNN_kNN_acc = sum(CNN_kNN_res[row(CNN_kNN_res) == col(CNN_kNN_res)]) / sum(CNN_kNN_res)
CNN_kNN_acc
```

```{r}
#14  Run the confusion matrix function and comment on the model output
library(caret)

confusionMatrix(as.factor(CNN_3NN), as.factor(CNN_comm_test$label), positive = "1", dnn=c("Prediction", "Actual"), mode = "sens_spec")
```
The accuracy of generally predicting whether or not something on TV is a commercial or not is 73.24%, which is around 13% better than our initial base rate of prediction at 63.92%. This means that without any general information about commercials, we would've been able to accurately predict whether something is a commercial or not a little over 60% of the time. However, our now trained model can predict whether or not something is a commercial or not accurately around 73% of the time. This is great, however accuracy takes into account both true positive and true negative rates, the latter of which we do not care as much about. We want to focus more on our skill and rate in being correct when guessing that something is a commercial. This is represented by Sensitivity, which for this 3-Nearest Neighbor model is 83.05%. The Specificity, which is correctly guessing something is not a commercial, is 55.24%. We want to be maximizing the Sensitivity percentage specifically because this will ensure our model is being trained to most best predict commercials. We want to be able to do this so that we can apply the model to our own commercials and see if it gets detected as one too. The rate of correctly predicting that something is not a commercial is not as important for the context of our scenario.

This will give us insight into what key characteristics commercials have in common, and what to not include or steer away from. We can then use this model on our commercials to see if they are still recognizable as commercials or if they are deemed as a TV show, the latter of which is what we want. The stronger the model the better to use, so that we can be as confident as possible that viewers too, will subconsciously classify our advertisements as TV shows, just as the model does. 

```{r}
#15 Run the "chooseK" function to find the perfect K, while using sapply() function on chooseK() to test k from 1 to 21 (only selecting the odd numbers), and set the train_set argument to 'commercial_train', val_set to 'commercial_test', train_class to the "label"   column of 'commercial_train', and val_class to the "label" column of 'commercial_test'. Label this  "knn_diff_k_com"

chooseK = function(k, train_set, val_set, train_class, val_class){
  
  # Build knn with k neighbors considered.
  set.seed(10271999)
  class_knn = knn(train = train_set,    #<- training set cases
                  test = val_set,       #<- test set cases
                  cl = train_class,     #<- category for classification
                  k = k,                #<- number of neighbors considered
                  use.all = TRUE)       #<- control ties between class assignments
                                        #   If true, all distances equal to the kth largest are included
  conf_mat = table(class_knn, val_class)
  
  # Calculate the accuracy.
  accu = sum(conf_mat[row(conf_mat) == col(conf_mat)]) / sum(conf_mat)                         
  cbind(k = k, accuracy = accu)
}

knn_diff_k_com = sapply(seq(1, 21, by = 2),  
                         function(x) chooseK(x, 
                                             train_set = CNN_comm_train[,1:7],
                                             val_set = CNN_comm_test[,1:7],
                                             train_class = CNN_comm_train$label,
                                             val_class = CNN_comm_test$label))

```

```{r}
#16 Create a dataframe so we can visualize the difference in accuracy based on K, convert the matrix to a dataframe
knn_diff_k_com = data.frame(k = knn_diff_k_com[1,],
                             accuracy = knn_diff_k_com[2,])
knn_diff_k_com
```

```{r}
#17 Use ggplot to show the output and comment on the k to select
library(ggplot2)

ggplot(knn_diff_k_com,
       aes(x = k, y = accuracy)) +
  geom_line(color = "orange", size = 1.5) +
  geom_point(size = 3)
```
Based off of the elbow graph that was generated with different k values for k-Nearest Neighbor, the graph begins to taper off with a reduced slope at a k value of 11. Thus, the optimal K value that we will be picking is 11.

```{r}
#18 Rerun the model  with "optimal" k 
CNN_11NN = knn(train = CNN_comm_train[, 1:7],
               test = CNN_comm_test[, 1:7],    
               cl = CNN_comm_train$label,
               k = 11,
               use.all = TRUE,
               prob = TRUE)
```

```{r}
#19 Use the confusion matrix function to measure the quality of the new model
confusionMatrix(as.factor(CNN_11NN), as.factor(CNN_comm_test$label), positive = "1", dnn=c("Prediction", "Actual"), mode = "sens_spec")
```

```{r}
#20 Summarize the differences in language Mr. Rooney may actually understand. Include a discussion on which approach k=3 or k="optimal" is the better method moving forward for "MEH". Most importantly draft comments about the over approach and model quality as it relates to addressing the problem proposed by Ed. 
```
The two approaches we are comparing here are 3-nearest neighbors or 11-nearest neighbors. As a quick overview, the method of K-Nearest Neighbors has a goal of predicting the label of a data point by looking at it's 'k' closest labeled data points (neighbors), with distance measured based on euclidean distance. A majority vote is used to determine the label, which is why odd numbers for k are most ideal to be using. This algorithm is memory/cased-based learning, and essentially uses the concept that similar inputs will map to similar outputs. We already know we can accurately predicted whether or not something is a commercial around 60% of the time, with no prior information. Our goal is to generate a model that can do so at a higher rate than this base rate.

For our purposes, the goal is to accurately predict whether or not something on TV is a commercial. There were many variables available in the CNN dataset that we had available for use in predicting the label for each row. However, some of these variables displayed correlations with one another, which is not ideal in the use of this algorithm as it will cause unnecessary noise in the model and bring bias that is not needed. Thus, after generating a correlation matrix we decided to take out 3 variables that displayed correlations above or below .7 and -.7, which we deemed 'strong'. Those were motion_distr_mn, spectral_flux_mn, and spectral_centroid_mn. That left us with 7 variables to be using for this algorithm. 

In conducting our analysis, while total accuracy is important in understanding the predictability of our model, we are more so interested in our model's Sensitivity, which is the rate at which we are correctly labeling that something is a commercial. This is because this will help us recognize the most important variables that help define the characteristics of a commercial so that MEH may better format their commercials to not include these aspects and mask itself as a TV show instead. We can then test our commercials on our model to see if it is still detected as a commercial. The more accurate we are with Sensitivity, the more reassured we can be that viewers will also be fooled into thinking the commercial is part of a TV show. 

Looking at the two models we've generated, 3-nearest neighbors has an accuracy rate of 73.24%, a Sensitivity rate of 83.05%, and a Specificity rate of 55.24%. 

11-nearest neighbors has an accuracy rate of 76.42%, a Sensitivity rate of 88.72%, and a Specificity rate of 53.86%.

For the purposes of this model, it seems better to move forward with the 11-nearest neighbors approarch given the almost 5% increase in Sensitivity from 3 to 11. This puts us at an almost 90% accuracy rate in labeling something a commercial when it truly is a commercial. This will help us in trying to best shape our commercial to be different than a classic one, and our model will be strong in predicting whether or not it is a commercial, allowing us to have a more robust manipulation in tricking our commercial as a TV show. 

However, there are some things to take into account. Based on the accuracy graph generated, it seems that a k of 9 would provide a similar accuracy level, and so if we want to play it safe with wanting to be more sensitive to noise, we may want to try to generate the model again with 9-nearest neighbors. However, our larger k-value is also better labeling with our discrete classes, although it could cause an overfit to a point of being too generalized. 

In this situation, the k=11 model is stronger than the k=3 model when focusing on Sensitivity, and thus the former should be picked to move forward with.